# Zev üîç

[![PyPI version](https://badge.fury.io/py/zev.svg)](https://badge.fury.io/py/zev)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Zev helps you remember (or discover) terminal commands using natural language.

![Description](./.github/demo.gif)

## üîß Installation

```bash
pip install zev
```

- **Note:** This project runs on top of LLM APIs like OpenAI, Google's Gemini, or [Ollama](https://ollama.com/).

## üì¶ Dependencies

For clipboard functionality (copying and pasting) to work properly, you may need to install:

- On Linux: `xclip` or `xsel` (for X11) or `wl-clipboard` (for Wayland)
- On macOS: No additional dependencies needed
- On Windows: No additional dependencies needed

## üéÆ Usage

#### Option 1: Interactive Mode

```bash
zev
```

#### Option 2: Direct Query

```bash
zev '<what you want to do>'
```

## üìù Examples

```bash
# Find running processes
zev 'show all running python processes'

# File operations
zev 'find all .py files modified in the last 24 hours'

# System information
zev 'show disk usage for current directory'

# Network commands
zev 'check if google.com is reachable'

# Git operations
zev 'show uncommitted changes in git'
```

## üõ°Ô∏è Safety Considerations

‚ö†Ô∏è Commands are generated by LLMs. While the tool attempts to flag dangerous commands, it may not always do so. Use caution.

![Example of dangerous command warning](./.github/dangerous_example.png)

## ‚öôÔ∏è Settings

### **Supported LLM Providers:**

- OpenAI
- Google Gemini
- Ollama

You can update your API keys and provider settings by running:

```bash
zev --setup
```

### OpenAI

To use OpenAI, you need an OpenAI account and a subscription. You can create an API key on [this page](https://platform.openai.com/settings/organization/api-keys).

### Google Gemini (Free)

To use Google's Gemini models, you need a Google AI Studio account. You can create a Gemini API key in [Google AI Studio](https://aistudio.google.com/).

## üê™ Using with Ollama

You can use Zev with [Ollama](https://ollama.ai/) as an alternative to hosted providers, which lets you run all commands locally. To set this up:

1. Install and start [Ollama](https://ollama.com/) with a model of your choice

2. Run `zev --setup` and put in the proper settings. For example:

```
? Pick your LLM provider: Ollama
? Enter the Ollama URL: http://localhost:11434/v1
? Enter the model to use (e.g. llama3.2): llama3.2
```

Note that to switch backends, you can re-run `zev --setup` again at any time.

## ü§ù Contributing

Contributions are welcome! Feel free to open issues or submit pull requests.

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
